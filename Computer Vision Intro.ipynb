{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision for Robotics\n",
    "\n",
    "In this tutorial you will be introduced to some basic concepts of computer vision and programming and have the chance to practice yourself.\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    "As you've found out by now, this tutorial is run using a jupyter notebook. This is an online programming environment which has been set up to take you through the tasks for this tutorial. Things to note with jupyter notebooks:\n",
    " - There are two types of 'cells', text cells like this one and code cells shown by the [?]: symbol at the side which contain the code that you'll run. As you go through feeel free to edit code cells and see what happens when you change them.\n",
    " - To run a cell press shift-enter or click the run button at the top of the page.\n",
    " - Sometimes you can accidentally enter editing mode of the text cells, if that happens just run the cell (shift-enter) to exit editing mode.\n",
    " - **Some cells refer to variables created in other cells so make sure to run all cells in order**, if you see an error message referring to a variable not found this is probably the issue\n",
    " \n",
    "This notebook is set up to run with the Python programming language. Different languages are structured and written differently which makes them good for different tasks, Python is a powerful language that's used a lot in research and is also relatively easy to start using.\n",
    "\n",
    "### Tutorial Structure\n",
    "\n",
    "This tutorial will give you a quick introduction to some core programming concepts and also some computer vision tasks. The first part will give and introduction to basic programming concepts, if you've done some programming before feel free to go over these quickly. The sections to this tutorial are:\n",
    " - Basic Programming Concepts\n",
    " - What are digital images?\n",
    " - Filtering an image\n",
    " - Edge detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Programming Concepts\n",
    "\n",
    "### Variables\n",
    "\n",
    "When programming, a piece of data has a a name and a data type. In this tutorial we'll use four data types:\n",
    " - int - Used for storing an integer, i.e. a whole number\n",
    " - float - Used for storing a floatimg point number, i.e. with decimal point\n",
    " - str - Used for storing a String, i.e. sequence of characters\n",
    " - list - Stores a comma separated list of data\n",
    " - array - Stores an array of data, we'll be using a library called 'numpy' which is useful for performing operations arrays. A library is some code written to perform specific operations, in this case the numpy library has useful inbuilt operation for dealing with large data arrays.\n",
    " \n",
    "In code you'll see two types of text, the actual code and comments. Comments are used to explain what's goin on in the code but aren't run by the program, in Python a comment is made by starting with the # symbol and are shown as italicised text. If you're not sure what some part of the code is doing try reading the comments for an explanation.\n",
    "\n",
    "The print statement is used to display a variable or message to the user. The structure is print( *variable name* ) or print( \"*message*\" ).\n",
    "\n",
    "The type() function isused to retrieve the type of a variable, e.g. type(*variable*)\n",
    "\n",
    "Try running the code cell below and make sure you understand where all the oupt statements are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np # Import the numpy library, name it np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"Hello, World!\") # print a message\n",
    "\n",
    "a = int() # Create blank int variable\n",
    "print(a) # print variable a\n",
    "print(type(a)) # print type of variable a\n",
    "\n",
    "a = 9 # Set value of a to 9\n",
    "b = 9.3 # Create a float\n",
    "c = a + b # basic arithmitic\n",
    "d = \"Hello, World!\" # Create a string\n",
    "e = [\"A list\", 6, 9.4, [\"A list\", \"In a list\"]] # A list\n",
    "f = np.array((4, 5)) # Create an array with 4 rows and 5 columns\n",
    "g = np.array([[1, 2, 3],[4, 5, 6]]) # Create an array with \n",
    "h = np.zeros((2, 3)) # Create an array of zeros\n",
    "i = np.ones((1, 6)) # Create an array of ones\n",
    "\n",
    "print(a, type(a)) # We can print more than one thing in a single line by separating the variables with a comma\n",
    "print(b, type(b))\n",
    "print(c, type(c))\n",
    "print(d, type(d))\n",
    "print(e, type(e))\n",
    "print(f, type(f), f.shape)\n",
    "print(g, type(g))\n",
    "print(h, type(h))\n",
    "print(i, type(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python we can select specific values in an array using square brackets []. The index of an array starts at 0, so the first element in a 1D array would be *array*[0]. 2D arrays are referenced with two indices, the first for the row number and the second for the column number, so to find the element in the 1st row and 3rd column we'd use *array*[0, 2]. To select an entire row or column we can use a colon, for example *array*[:, 1] would select all rows and the second column. This can also be extended to select a range of values (called a slice), for example *array*[0:3, 1:2]. Finally, elements can be referenced from the end of an array dimension by using negative indices, for example the last element in the first row could be found using *array*[0, -1].\n",
    "\n",
    "This is best seen in practice, try changing values below to see what happens for different values. What happens if you try to use an index to large for the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3],[4, 5, 6]])\n",
    "print(A)\n",
    "print(A[0, 2])\n",
    "print(A[:, 1])\n",
    "print(A[1, 0:2])\n",
    "print(A[0, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Structure: if, for, while\n",
    "\n",
    "Code can be thought of as a flowchart with one instruction being executed at a time. In order to make decision we commonly use 'if' statements and to repeat sections of code we use 'while' loops or 'for' loops.\n",
    "\n",
    "If statements are used with conditional operators to decide of a block of code should be executed. The operators must always be either true or false:\n",
    " - Equals: a == b\n",
    " - Not Equal: a != b\n",
    " - Less than: a < b\n",
    " - Less than or equal to: a <= b\n",
    " - Greater than: a > b\n",
    " - Greater than or equal to: a >= b\n",
    "\n",
    "If statements can be followed by multiple 'elif' statements (short for else if) to which are evaluated of the previous statements are false. 'else' statements are used to execute code if none of the previous if or elif statements have been executed.\n",
    "\n",
    "Run the example below and make sure you're happy with where the ouputs are coming from and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5\n",
    "b = 9\n",
    "\n",
    "if a == 5:\n",
    "    print(\"a equals five\")\n",
    "\n",
    "if a >= 5:\n",
    "    print(\"a is greater than or equal to 5\")\n",
    "    \n",
    "if a < 5:\n",
    "    print(\"a is less than 5\")\n",
    "elif b >= a:\n",
    "    print(\"b is greater than or equal to a\")\n",
    "\n",
    "if b < a:\n",
    "    print(\"b is less than a\")\n",
    "elif b == a:\n",
    "    print(\"b equals a\")\n",
    "else:\n",
    "    print(\"b is greater than a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops are used to repeat sections of code, as we'll see they're important for image processing. \n",
    "\n",
    "'For' loops repeat the section of code a set number of times. This is often used with the 'range' function to define the range of values to iterate over, note range(0, 5) iterates over the values 0 to 4 not 0 to 5. For loops can also be used to iterate over the items in a list.\n",
    "\n",
    "'while' loops are used to repeat a section of code until a condition is met. The conditional statements that can be used are the same as for the 'if' statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(0, 10): # for values in the range 0 - 10 (not including 10) set a to the current value and print out a\n",
    "    print(a)\n",
    "    \n",
    "B = [\"Hello\", \"World\", 2, 6.8, [\"Another\", \"List\"]] # Create a list called B with different types of data in it\n",
    "for b in B: # Loop through list B, set the value of b to the current item and print out b\n",
    "    print(b)\n",
    "    \n",
    "b = 0\n",
    "while b < 10: # Keep looping through if b is less than 10 (this would loop forever if we removed the 'b = b + 1' line)\n",
    "    print(b)\n",
    "    b = b + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and viewing images\n",
    "\n",
    "We'll be using an image handling library called opencv to manage our images. Let's get going by loading and viewing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_im = cv2.imread(\"peppers.png\") # Load the image saved as 'peppers.png' into the variable called colour_im\n",
    "colour_im = cv2.cvtColor(colour_im, cv2.COLOR_BGR2RGB) # The image was saved in Blue-Green-Red format, convert it to Red-Blue-Green format\n",
    "plt.imshow(colour_im) # Draw the image\n",
    "plt.show() # Show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the last lecture, computer images are just arrays of data. Run the code below and see how the colour image is saved as an array with 512x512 pixels and 3 channels for red, green and blue.\n",
    "\n",
    "The code then converts the image to greyscale, see how the array changes shape to only have one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW_im = cv2.cvtColor(colour_im, cv2.COLOR_RGB2GRAY) # convert colour image to greyscale\n",
    "\n",
    "print(colour_im.shape) # print the size of the colour image in pixels, note it has 3 channels\n",
    "print(BW_im.shape) # print the size of the greyscale image, note it only has one channel\n",
    "print(np.max(BW_im), np.min(BW_im)) # find the min and max values in the greyscale image, should be between 0 and 255\n",
    "\n",
    "plt.imshow(BW_im, cmap='gray') # Draw and show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select specific regions of an  image easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(BW_im[0:200, 0:200], cmap='gray') # Draw and show the first 200 rows and columns of pixels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Now we can use this to do useful things to images. We're going to start with a method of filtering images to help remove noise. Salt and pepper noise is where an image has random pixels that are set to black or white, the image below shows an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW_noise = cv2.imread(\"peppers_BW_noise.png\", 0) # Load image with noise, set it to variable 'BW_noise'\n",
    "plt.imshow(BW_noise, cmap='gray') # Draw and show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of dealing with salt and pepper noise is to apply a median filter. In a median filter a small window (known as a kernel) is moved over an image with the centre pixel set to the median of the values in the window. This assumes that most values in an image are similar to those close to it so using the median should remove the 'pulses' of black or white.\n",
    "\n",
    "In code we'll use two for loops to move our kernel over the image. The first for loop will move the kernel down the rows one at a time and the second will move the kernel across the rows one at a time. At each point we'll set the centre pixel to the median of all the pixels in the window. \n",
    "\n",
    "The code below implements this with a 3x3 kernel, run the code and read over it to check you understand what is happening, you should see the noise from the image is removed so it looks like the original grayscale image. The code might take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3 # Set size of kernel\n",
    "\n",
    "pix_range = int(kernel_size/2) \n",
    "filter_im = np.zeros((BW_noise.shape[0], BW_noise.shape[1])) # create array of zeros with same shape as input image\n",
    "\n",
    "for y in range(0+pix_range, BW_noise.shape[0]-pix_range): # Loop through all viable rows for given kernel size\n",
    "    for x in range(0+pix_range, BW_noise.shape[1]-pix_range): # Loop through all viable columns for given kernel size\n",
    "        window = BW_noise[y-pix_range:y+pix_range+1, x-pix_range:x+pix_range+1] # select window with size of kernel centred around current pixel from noisy image  \n",
    "        filter_im[y, x] = np.median(window) # Set current pixel in filtered image to median of window\n",
    "\n",
    "plt.imshow(filter_im, cmap='gray') # Draw and show the filtered image\n",
    "plt.show()\n",
    "plt.imshow(BW_im, cmap='gray') # Draw and show the original image without noise for comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have found that the code took a few seconds to run as iterating over every pixel takes a while with the for loops. Luckily the opencv library has a median filter built in which much more efficient and only needs one line of code for us to run. You should find the code below runs faster than the one we had before.\n",
    "\n",
    "Try changing the kernel size, as it gets larger you should see more noise is removed but the image also starts to become blurry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "filter_im = np.zeros((BW_noise.shape[0], BW_noise.shape[1]))\n",
    "\n",
    "filter_im = cv2.medianBlur(BW_noise, kernel_size)\n",
    "\n",
    "plt.imshow(filter_im, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(BW_im, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "\n",
    "One of the key uses of computer vision in robotics is to try and find objects in images. To do this it's important to find edges in images where sudden changes in intensity show where an object might start or end.\n",
    "\n",
    "We saw the Prewitt edge detector in the lecture, let's see it in action. To start we have a simple image of a grid, see how the x kernel detects horizontal lines and the y kernel detects veretical lines.\n",
    "\n",
    "In the code below, the 'cv2.filter2D' function performs the same action we saw before of running teh kernel over every pixel in the image. Using this function runs faster and shorter to write than using multiple 'for' loops every time.\n",
    "\n",
    "Using the kernel below, an edge going from black (0) to white (255) will give a value of -765, whereas an edge going from white to black 765 and an area of uniform colour will be 0. When the image is displayed this range is scaled to the range 0-255 so white to black edges show up as white(255), black to white edges show up as black(0) and uniform areas are grey(128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_im = cv2.imread(\"grid.png\", 0) # Read the image from file\n",
    "\n",
    "plt.imshow(grid_im, cmap='gray') # Draw and show the image\n",
    "plt.show()\n",
    "\n",
    "# Create the x and y kernels\n",
    "kernelx = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "kernely = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "print(kernelx)\n",
    "print(kernely)\n",
    "\n",
    "pix_range = int(kernelx.shape[0]/2) \n",
    "sobel_x = np.zeros((grid_im.shape[0], grid_im.shape[1])) # create array of zeros with same shape as input image\n",
    "sobel_y = np.zeros((grid_im.shape[0], grid_im.shape[1])) # create array of zeros with same shape as input image\n",
    "\n",
    "for y in range(0+pix_range, grid_im.shape[0]-pix_range): # Loop through all viable rows for given kernel size\n",
    "    for x in range(0+pix_range, grid_im.shape[1]-pix_range): # Loop through all viable columns for given kernel size\n",
    "        window = grid_im[y-pix_range:y+pix_range+1, x-pix_range:x+pix_range+1] # select window with size of kernel centred around current pixel from noisy image  \n",
    "        sobel_x[y, x] = np.sum(kernelx * window) # Multiply window by x kernel and sum all elements\n",
    "        sobel_y[y, x] = np.sum(kernely * window) # Multiply window by y kernel and sum all elements\n",
    "\n",
    "plt.imshow(sobel_x, cmap='gray') # Draw and show the original image without noise for comparison\n",
    "plt.show()\n",
    "plt.imshow(sobel_y, cmap='gray') # Draw and show the original image without noise for comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the median filter, the opencv library has already got a sobel filtering function (cv2.Sobel(...)) implemented that is shorter to write and runs faster than the code above. \n",
    "\n",
    "If we don't care about the direction of a gradient we take the magnitude tp combine the two x and y gradients:\n",
    "\n",
    "\\begin{equation}\n",
    "magnitude = \\sqrt{x^{2} + y^{2}}\n",
    "\\end{equation}\n",
    "\n",
    "It's also good practice to rescale the image range from 0-765 back to 0-255 so we can use standard manipulations. The code below implements all these changes, you can see it's much neater than the code above with the for loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_im = cv2.imread(\"grid.png\", 0) # Read the image from file\n",
    "\n",
    "plt.imshow(grid_im, cmap='gray') # Draw and show the image\n",
    "plt.show()\n",
    "\n",
    "# Apply x and y sobel filters\n",
    "img_sobelx = cv2.Sobel(grid_im, cv2.CV_64F, 1, 0, ksize = 3)\n",
    "img_sobely = cv2.Sobel(grid_im, cv2.CV_64F, 0, 1, ksize = 3)\n",
    "\n",
    "mag = np.sqrt(np.square(img_sobelx) + np.square(img_sobely)) # Find magnitude of x and y components\n",
    "img_sobel = np.uint8(mag) # convert gradient scale to an 8bit integer (range 0-255)\n",
    "\n",
    "plt.imshow(img_sobelx, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(img_sobely, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(img_sobel, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now take the functions we've used so far and apply them to a more realistic scenario. One use of edge detection in robotics is for navigation, either on a mobile robot or a driverless car. By following lines marked on the ground a robot can navigate around a builing or roads. For this example we'll take an example from a line following robot where we need to locate the lines within the image. After the lines have been located the robot would then perform some more processing to work out which direction they point and which way to drive.\n",
    "\n",
    "<img src=\"robot_line_raw.jpeg\" width=\"240\" height=\"240\" align=\"center\"/>\n",
    "\n",
    "Image taken from this article, worth reading for more information on a real scenario: https://becominghuman.ai/autonomous-racing-robot-with-an-arduino-a-raspberry-pi-and-a-pi-camera-3e72819e1e63\n",
    "\n",
    "Read through and run the code below, check you understand what's happening at each step. Try changing the parameters at the top and see how the result changes. \n",
    "\n",
    "The overall sequence can be summarised as:\n",
    " - Filter image to reduce noise\n",
    " - Apply sobel filter to detect edges\n",
    " - Threshold the edges - This will remove edges that are less intense than the threshold value\n",
    " - Apply Hough transform to find long straight lines in image* \n",
    " \n",
    " \n",
    "*We haven't convered this step in detail, feel free to research this further if you would like. The basic principle is to find all the lines in the thresholded image that meet certain requirements on length, straightness, etc. If you'd like to read more try this link: https://medium.com/@tomasz.kacmajor/hough-lines-transform-explained-645feda072ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to try changing:\n",
    "median_filter_size = 3 # Set median kernel size\n",
    "threshold = 100 # Set edge intensity threshold\n",
    "sobel_k_size = 3\n",
    "\n",
    "# Load image from  file, convert colour type and display\n",
    "robot_line_im = cv2.imread(\"robot_line_raw.jpeg\")\n",
    "robot_line_im = cv2.cvtColor(robot_line_im, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(robot_line_im)\n",
    "plt.show()\n",
    "\n",
    "# convert colour image to greyscale and apply median filter\n",
    "robot_line_bw = cv2.cvtColor(robot_line_im, cv2.COLOR_RGB2GRAY) \n",
    "robot_line_bw_median = cv2.medianBlur(robot_line_bw, median_filter_size)\n",
    "plt.imshow(robot_line_bw_median, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Apply sobel filter\n",
    "img_sobelx = cv2.Sobel(robot_line_bw_median, cv2.CV_64F, 1, 0, ksize = sobel_k_size)\n",
    "img_sobely = cv2.Sobel(robot_line_bw_median, cv2.CV_64F, 0, 1, ksize = sobel_k_size)\n",
    "mag = np.sqrt(np.square(img_sobelx) + np.square(img_sobely))\n",
    "img_sobel = np.uint8(mag)\n",
    "plt.imshow(img_sobel, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Apply threshold to edge detection image, any edges with intensity greater than the threshold value are set to 255 (white) and those not are set to 0 (black)\n",
    "_, threshold_im = cv2.threshold(img_sobel.astype(float), threshold, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(threshold_im, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Use Hough transform to find straight lines in threshold image\n",
    "lines = cv2.HoughLinesP(threshold_im.astype(np.uint8), 1, np.pi/180, 135, minLineLength=160, maxLineGap=10)\n",
    "\n",
    "# Draw red lines on the original image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(robot_line_im, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "#Show resultant image\n",
    "plt.imshow(robot_line_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's it for this coding exercise. If you'd like to know more about image processing there are lots of useful introductions online so try implementing some functions yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
